\section{Conclusion}
\section*{Conclusion}

This study evaluated the performance of KNN, SVM, and various training reduction techniques on multiple datasets. Our analysis aimed to identify optimal configurations for each algorithm and assess the impact of specific parameters on classification accuracy and computational efficiency.

In terms of KNN, no single value of $k$ stood out as universally optimal across all datasets, although certain values performed better on specific datasets. For instance, k=7 demonstrated slightly improved results. However, these differences were not statistically significant, suggesting that the choice of $k$ has limited impact in this context.

Among the different KNN algorithms evaluated, no specific distance metric or voting scheme showed a substantial advantage across datasets, with equal weighting generally yielding favorable results. Voting schemes, while commonly used to resolve query decisions, did not significantly enhance accuracy in this study, indicating that simpler configurations may suffice for these datasets. Additionally, the similarity functions used (e.g., Euclidean, Manhattan) did not exhibit major differences in effectiveness across datasets, further supporting the robustness of KNN under various parameter settings.

For SVM, we observed that different kernel functions produced varying results depending on the dataset. In the hepatitis dataset, the sigmoid kernel with $C=100.0$ achieved the highest accuracy and F1 score, making it the optimal choice for that dataset. In contrast, for the mushroom dataset, multiple configurations achieved perfect accuracy, indicating limited complexity in the data. Thus, the selection of the best kernel can vary with dataset characteristics, though the sigmoid kernel performed well in our tests.

When comparing KNN with reduced datasets to the original KNN, we observed that training reduction techniques often resulted in decreased accuracy. Specifically, the GCNN reduction method led to the most noticeable decline in classification performance, followed by DROP3, while EENTH performed comparably to the original datasets. EENTHâ€™s role in reduction is primarily to remove noisy instances, achieving moderate reduction while maintaining accuracy. In contrast, DROP3 and GCNN are more aggressive techniques, achieving higher reduction percentages (fewer samples retained) but at the cost of a greater impact on classification performance. This suggests that EENTH may be suitable when balancing accuracy with noise reduction, whereas DROP3 and GCNN may be appropriate for applications prioritizing dataset compactness over accuracy.

In SVM, reducing the training set with these techniques also affected performance, with the most significant reductions observed when using GCNN. Among the training reduction methods, EENTH provided more insight into the underlying dataset structure by selectively removing noise while preserving accuracy. Its ability to maintain accuracy with fewer data points makes it a valuable tool for understanding data patterns without excessive computational demand, however it didn't affect execution time positively as it is not a lazy learning techniques.

Feature selection, though often beneficial for high-dimensional data, was not applied in this study as it was out of scope. However, it could potentially yield better results by reducing complexity and enhancing interpretability without significantly altering the training set size. Based on our findings, feature selection may be preferable over certain reduction methods for balancing data simplification and accuracy preservation, though further study would be needed to confirm this hypothesis.

In summary, our results indicate that KNN weighting, specific SVM configurations, and certain training reduction techniques significantly influence model performance but that each dataset requires its own refining for getting the best specific results. This study provides a framework for selecting machine learning methods and configurations based on dataset characteristics, supporting the development of effective and computationally efficient models.