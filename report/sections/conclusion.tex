\section{Conclusion}

This study evaluated the performance of KNN, SVM, and various training reduction techniques on multiple datasets. Our analysis aimed to identify optimal configurations for each algorithm and assess the impact of specific parameters on classification accuracy and computational efficiency.

First, we performed an in-depth evaluation on the different configurations of the KNN model. Our analysis found no evidence that the choice of k significantly impacts accuracy, although certain specific trends are observed for each dataset. Similarly, no significant differences were found among different distance metrics or voting policies. Notably, however, it is consistently observed that the weighting method does have a significant impact on KNN accuracy, with a favorable trend toward equal weighting.

For SVM, we observed that different kernel functions produced varying results depending on the dataset. In the hepatitis dataset, the sigmoid kernel with $C=100.0$ achieved the highest accuracy and F1 score, making it the optimal choice for that dataset. In contrast, for the mushroom dataset, multiple configurations achieved perfect accuracy, indicating limited complexity in the data.

Despite the limitations in the statistical conclusions of the comparison between the best SVM and KNN methods for each dataset, primarily due to limited variation in the metrics used, the results adequately capture the nature of each method. In the hepatitis dataset, it was concluded with precision that the \textit{f1 score} was higher for SVM compared to KNN. Given the medical nature of this data, achieving a higher \textit{f1 score} is crucial, as it indicates that the model has both high precision and recall, correctly identifying positive cases without generating excessive false alarms. In the mushroom dataset, however, no significant differences were observed: both SVM and KNN achieved 100$\%$ in accuracy and \textit{f1 score} across all tests. The most relevant difference between these two algorithms was in execution time, as shown by the Wilcoxon test. This result aligns with expectations, as KNN is a \textit{lazy learning} method, while SVM is \textit{eager learning}.

We have also compared the performance of the KNN classifier when training it on reduced datasets instead of the original training sets. From this study we consistently found significant differences across the various reduction methods. GCNN consistently resulted in poorer classification performance compared to the original datasets. DROP3 also appeared to reduce performance, though less conclusively than GCNN. In contrast, EENTH showed no significant difference from the original datasets, suggesting it may be advantageous, by achieving statistically similar results with fewer samples.

When evaluating the performance of the SVM classifier over the reduced datasets, we obtained similar results as with the KNN. With the Hepatitis dataset, the GCNN and DROP3 caused worse performance while EENTH showed no meaningful difference with the original training set. On the Mushroom dataset, there was not enough variance between the metrics to apply the statistical tests; nevertheless, the mean values of the metrics show very similar performance for all the reduction methods, which leads us to conclude again that there is no significant differences between the reduction mehtods.

Feature selection, though often beneficial for high-dimensional data, was not applied in this study as it was out of scope. However, it could potentially yield better results by reducing complexity and enhancing interpretability without significantly altering the training set size. Based on our findings, feature selection may be preferable over certain reduction methods for balancing data simplification and accuracy preservation, though further study would be needed to confirm this hypothesis.

In summary, our results indicate that feature weighting on KNN, specific SVM configurations, and certain training reduction techniques may significantly influence model performance but that each dataset requires its own refining for getting the best specific results. This study provides a framework for selecting machine learning methods and configurations based on dataset characteristics, supporting the development of effective and computationally efficient models. 